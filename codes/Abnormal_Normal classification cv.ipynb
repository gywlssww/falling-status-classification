{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import isdir\n",
    "import os\n",
    "import pandas as pd\n",
    "abnormal=[]\n",
    "normal=[]\n",
    "for x in glob('../data/*/*걷기 무게중심*'):\n",
    "    abnormal.append(x)\n",
    "for x in glob('../data/*/*걷기_보통*'):\n",
    "    normal.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "scale_columns=['x','y','z']\n",
    "print(len(abnormal))\n",
    "print(len(normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>시간(ms)</th>\n",
       "      <th>이름</th>\n",
       "      <th>허리인치</th>\n",
       "      <th>키</th>\n",
       "      <th>회차</th>\n",
       "      <th>낙상종류</th>\n",
       "      <th>방향</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>고대석</td>\n",
       "      <td>72kg</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>걷기</td>\n",
       "      <td>보통</td>\n",
       "      <td>644</td>\n",
       "      <td>15552</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>고대석</td>\n",
       "      <td>72kg</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>걷기</td>\n",
       "      <td>보통</td>\n",
       "      <td>-3835</td>\n",
       "      <td>11648</td>\n",
       "      <td>6848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>고대석</td>\n",
       "      <td>72kg</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>걷기</td>\n",
       "      <td>보통</td>\n",
       "      <td>-3259</td>\n",
       "      <td>15040</td>\n",
       "      <td>3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>202</td>\n",
       "      <td>고대석</td>\n",
       "      <td>72kg</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>걷기</td>\n",
       "      <td>보통</td>\n",
       "      <td>-123</td>\n",
       "      <td>16256</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>고대석</td>\n",
       "      <td>72kg</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>걷기</td>\n",
       "      <td>보통</td>\n",
       "      <td>1604</td>\n",
       "      <td>12160</td>\n",
       "      <td>2816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  시간(ms)   이름  허리인치    키  회차 낙상종류  방향     x      y     z\n",
       "0           0      70  고대석  72kg  168   1   걷기  보통   644  15552  7488\n",
       "1           1     127  고대석  72kg  168   1   걷기  보통 -3835  11648  6848\n",
       "2           2     164  고대석  72kg  168   1   걷기  보통 -3259  15040  3968\n",
       "3           3     202  고대석  72kg  168   1   걷기  보통  -123  16256  3904\n",
       "4           4     258  고대석  72kg  168   1   걷기  보통  1604  12160  2816"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(open(normal[0], 'rb'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df=pd.DataFrame()\n",
    "X_test_df=pd.DataFrame()\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "for f in abnormal:\n",
    "    df=pd.read_excel(open(f, 'rb'))  \n",
    "    X_train_df=X_train_df.append(df.loc[:1112,scale_columns],ignore_index=True)\n",
    "    X_test_df=X_test_df.append(df.loc[1112:1391,scale_columns])\n",
    "for f in normal:\n",
    "    df=pd.read_excel(open(f, 'rb'))  \n",
    "    X_train_df=X_train_df.append(df.loc[:1112,scale_columns])\n",
    "    X_test_df=X_test_df.append(df.loc[1112:1391,scale_columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train, X_test (44520:11131 / 11199: 2800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330</td>\n",
       "      <td>15488</td>\n",
       "      <td>6272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1842</td>\n",
       "      <td>12480</td>\n",
       "      <td>4608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1293</td>\n",
       "      <td>11264</td>\n",
       "      <td>3712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1805</td>\n",
       "      <td>13760</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2317</td>\n",
       "      <td>14464</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x      y     z\n",
       "0  1330  15488  6272\n",
       "1  1842  12480  4608\n",
       "2 -1293  11264  3712\n",
       "3 -1805  13760  3520\n",
       "4 -2317  14464  3648"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>-2061</td>\n",
       "      <td>17856</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>50</td>\n",
       "      <td>18752</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>-1101</td>\n",
       "      <td>17024</td>\n",
       "      <td>8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>9266</td>\n",
       "      <td>10240</td>\n",
       "      <td>7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>-461</td>\n",
       "      <td>14656</td>\n",
       "      <td>7424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x      y     z\n",
       "1112 -2061  17856   832\n",
       "1113    50  18752  6400\n",
       "1114 -1101  17024  8064\n",
       "1115  9266  10240  7168\n",
       "1116  -461  14656  7424"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_train, y_test ( 0: abnormal, 1: normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "y_test=[]\n",
    "for i in range(55650):\n",
    "    if i <=44520:\n",
    "        y_train.append(0) #비정상\n",
    "    else:\n",
    "        y_train.append(1) #정상\n",
    "for i in range(13999):\n",
    "    if i <=11199:\n",
    "        y_test.append(0) #비정상\n",
    "    else:\n",
    "        y_test.append(1) #정상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "scaler = scaler.fit(X_train_df)\n",
    "\n",
    "X_train_df = scaler.transform(\n",
    "  X_train_df.to_numpy()\n",
    ")\n",
    "\n",
    "X_test_df= scaler.transform(\n",
    "  X_test_df.to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55650, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55650, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_train=np.array(y_train).reshape(-1,1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        labels = y[i + time_steps]\n",
    "        Xs.append(v)\n",
    "        ys.append(labels)\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 233\n",
    "STEP = 40\n",
    "\n",
    "X_train, y_train = create_dataset(\n",
    "    X_train_df,\n",
    "    y_train,\n",
    "    TIME_STEPS,\n",
    "    STEP\n",
    ")\n",
    "\n",
    "X_test, y_test = create_dataset(\n",
    "    X_test_df,\n",
    "    y_test,\n",
    "    TIME_STEPS,\n",
    "    STEP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 233, 3)\n",
      "(1386, 1)\n",
      "(345, 233, 3)\n",
      "(345, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "      keras.layers.LSTM(\n",
    "          units=64,\n",
    "          input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "      )\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 233, 50)           10800     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 32,301\n",
      "Trainable params: 32,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "model.add(LSTM(50, return_sequences= False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
    "model.summary()\n",
    "# h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do - hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "      keras.layers.LSTM(\n",
    "          units=128,\n",
    "          input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "      )\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Bidirectional(\n",
    "      keras.layers.LSTM(\n",
    "          units=128,\n",
    "          input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "      )\n",
    "    ))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_dataset(X, y, time_steps=1, step=1):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(0, len(X) - time_steps, step):\n",
    "            v = X[i:(i + time_steps)]\n",
    "            labels = y[i + time_steps]\n",
    "            Xs.append(v)\n",
    "            ys.append(labels)\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "create_dataset(DATA['x','y','z'],DATA['낙상종류'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "class TimeBasedCV(object):\n",
    "    '''\n",
    "    Parameters \n",
    "    ----------\n",
    "    train_period: int\n",
    "        number of time units to include in each train set\n",
    "        default is 30\n",
    "    test_period: int\n",
    "        number of time units to include in each test set\n",
    "        default is 7\n",
    "    freq: string\n",
    "        frequency of input parameters. possible values are: days, months, years, weeks, hours, minutes, seconds\n",
    "        possible values designed to be used by dateutil.relativedelta class\n",
    "        deafault is days\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, train_period=30, test_period=7, freq='seconds'):\n",
    "        self.train_period = train_period\n",
    "        self.test_period = test_period\n",
    "        self.freq = freq\n",
    "\n",
    "        \n",
    "        \n",
    "    def split(self, data, validation_split_date=None, date_column='시간(ms)', gap=0):\n",
    "        '''\n",
    "        Generate indices to split data into training and test set\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        data: pandas DataFrame\n",
    "            your data, contain one column for the record date \n",
    "        validation_split_date: datetime.date()\n",
    "            first date to perform the splitting on.\n",
    "            if not provided will set to be the minimum date in the data after the first training set\n",
    "        date_column: string, deafult='record_date'\n",
    "            date of each record\n",
    "        gap: int, default=0\n",
    "            for cases the test set does not come right after the train set,\n",
    "            *gap* days are left between train and test sets\n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        train_index ,test_index: \n",
    "            list of tuples (train index, test index) similar to sklearn model selection\n",
    "        '''\n",
    "        \n",
    "        # check that date_column exist in the data:\n",
    "        try:\n",
    "            data[date_column]\n",
    "        except:\n",
    "            raise KeyError(date_column)\n",
    "                    \n",
    "       \n",
    "        \n",
    "        \n",
    "    def create_dataset(X, y, time_steps=1, step=1):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(0, len(X) - time_steps, step):\n",
    "            v = X[i:(i + time_steps)]\n",
    "            labels = y[i + time_steps]\n",
    "            Xs.append(v)\n",
    "            ys.append(labels)\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    \n",
    "    def get_n_splits(self):\n",
    "        \"\"\"Returns the number of splitting iterations in the cross-validator\n",
    "        Returns\n",
    "        -------\n",
    "        n_splits : int\n",
    "            Returns the number of splitting iterations in the cross-validator.\n",
    "        \"\"\"\n",
    "        return self.n_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeBasedCV(train_period=30,\n",
    "                   test_period=7,\n",
    "                   freq='days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
